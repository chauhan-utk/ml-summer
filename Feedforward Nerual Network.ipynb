{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_size = 784\n",
    "hidden_size = 250\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 150\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root=\"./datasets/\",\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dataset = dsets.MNIST(root=\"./datasets/\",\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the class for Feed Forward Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = Net(input_size=in_size, hidden_size=hidden_size,\n",
    "          num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (fc1): Linear (784 -> 250)\n",
      "  (relu): ReLU ()\n",
      "  (fc2): Linear (250 -> 10)\n",
      ")\n",
      "Linear (784 -> 250)\n",
      "ReLU ()\n",
      "Linear (250 -> 10)\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(net.modules()):\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blah = train_l.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 1, 28, 28])\n",
      "torch.Size([150])\n"
     ]
    }
   ],
   "source": [
    "print(blah[0].size())\n",
    "print(blah[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blah2 = torch.FloatTensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/400], Loss: 0.3615\n",
      "Epoch [1/5], Step [200/400], Loss: 0.3481\n",
      "Epoch [1/5], Step [300/400], Loss: 0.2876\n",
      "Epoch [1/5], Step [400/400], Loss: 0.1619\n",
      "Epoch [2/5], Step [100/400], Loss: 0.2164\n",
      "Epoch [2/5], Step [200/400], Loss: 0.2342\n",
      "Epoch [2/5], Step [300/400], Loss: 0.0829\n",
      "Epoch [2/5], Step [400/400], Loss: 0.1586\n",
      "Epoch [3/5], Step [100/400], Loss: 0.0717\n",
      "Epoch [3/5], Step [200/400], Loss: 0.0694\n",
      "Epoch [3/5], Step [300/400], Loss: 0.1169\n",
      "Epoch [3/5], Step [400/400], Loss: 0.1062\n",
      "Epoch [4/5], Step [100/400], Loss: 0.0360\n",
      "Epoch [4/5], Step [200/400], Loss: 0.0823\n",
      "Epoch [4/5], Step [300/400], Loss: 0.0540\n",
      "Epoch [4/5], Step [400/400], Loss: 0.0860\n",
      "Epoch [5/5], Step [100/400], Loss: 0.0491\n",
      "Epoch [5/5], Step [200/400], Loss: 0.0337\n",
      "Epoch [5/5], Step [300/400], Loss: 0.1119\n",
      "Epoch [5/5], Step [400/400], Loss: 0.0565\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Convert torch tensor to Variable\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size,\n",
    "                     loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%'\n",
    "      % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the Model\n",
    "# torch.save(net.state_dict(), \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.2578  0.2810  1.0098\n",
      " 0.6320 -1.3269  0.2230\n",
      " 1.0321  0.1511  0.4091\n",
      " 2.0378  0.6811  0.2187\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "(\n",
      " 1.0098\n",
      " 0.6320\n",
      " 1.0321\n",
      " 2.0378\n",
      "[torch.FloatTensor of size 4x1]\n",
      ", \n",
      " 2\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 4x1]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "blah = torch.randn(4,3)\n",
    "print(blah)\n",
    "print(torch.max(blah,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-9ebe55620e82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                 requires_grad=True)\n\u001b[0;32m      8\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chauh\\anaconda2\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 raise RuntimeError(\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[1;34m'backward should be called only on a scalar (i.e. 1-element tensor) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                     'or with gradient w.r.t. the variable')\n\u001b[0;32m    139\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x = Variable(torch.cuda.FloatTensor(np.random.randn(4,3)),\n",
    "                requires_grad=True)\n",
    "    y = Variable(torch.cuda.FloatTensor(np.random.randn(4,3)),\n",
    "                requires_grad=True)\n",
    "    z = x*2 + y*3\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
